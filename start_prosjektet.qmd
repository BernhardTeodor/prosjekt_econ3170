---
title: "Titanic"
format: pdf
editor: visual
---

# Prosjekt econ 3170/4170

## Pakker

I prosjektet kommer vi hovedsakelig til å benytte oss av to pakker: tidyverse og tidymodels. Begge pakkene er samlinger av mange ulike pakker. Vi skal bruke Tidyverse til å manipulere data og visualisering. Tidymodels skal vi bruke til maskinlæring.

```{r echo = T, results = 'hide'}
library(tidyverse)
library(tidymodels)
```

## Data

```{r echo = T, results = 'hide'}
titanic <- read_csv("Titanic-Dataset.csv")
```

Vi benytter oss av data fra kaggel: <https://www.kaggle.com/competitions/titanic/data>.

Datasettet består av 12 kolonner. Her kommer en liten oversikt over hva de betyr:

-   Survival: Om vedkommende overlevde: 1 = Ja, 0 = Nei.

-   Pclass: 1, 2 eller 3.klasse.(1 er best)

-   Sex: Kjønn

-   Age: Alder

-   Sibsp: Antall søsken/ ektefeller på Titanic

-   Parch: Antall foreldre/ barn på Titanic

-   Ticket: Billettnummer

-   Fare: Pris

-   Cabin: Lugarnummer

-   Embarked: Hvor de gikk ombord: C = Cherbourg, Q = Queenstown, S = Southampton.

-   Name

-   PassengerId: Satt inn av Kaggle for å få oversikt over passasjerer.

```{r}
head(titanic)
```

Pclass og Fare er variabler som virker spennende. Hvis man har sett Titanic-filmen, blir det tydelig framstilt at de som er i første klasse hadde en stor fordel da det kom til evakuering. Det er nok trolig at variabelen Fare har en sterk korrelasjon med Pclass. Summen du betalte for billetten din reflekterer nok hvilken klasse du er i. Dette kan igjen si noe om sannsynligheten for å overleve.

Cabin og Ticket er variable, det blir vanskelig å si noe. På mange måter reflekterer de nok Pclass og Fare. Det er imidlertid vanskelig å konkludere om overlevelse, basert på billettnummer. Den spesifikke lugaren er kanskje ikke så interessant, men hvilket dekk den ligger på kan være relevant. På den andre siden kan man si at dette kommer tydligere fram i Pclass.

Alder og kjønn er viktige variabler, spesielt med tanke på uttrykket "Kvinner og barn først" ved evakuering. Her kan det også være en mulighet å manipulere dataen, for å fremheve at noen f.eks. er barn eller gamle.

Variabelen navn er litt "tricky". Hva noen heter burde strengt tatt ikke ha så mye å si for overlevelsessjansene. Likevel inkluderer navnene titler som f.eks. mrs og master, og dette kan igjen være interessant. Samtidig har vi jo også variabler som kjønn og alder. Hvor stor betydning navnet har, er nok litt vanskelig å si.

Embarked er en variabel det er litt vanskelig å si noe om. Det er kun tre forskjellige tre forskjellige steder. Det burde strengt tatt ikke ha noe særlig stor betydning for at man overlever eller ikke. På den andre siden, kan det være en sammenheng mellom hvor man steg ombord og hvilken klasse man er i.

Parch og Sibsp er to variabler som forteller mye av det samme, men likevel interessante. Vil det ha noe betydning for egen overlevelse hvis man har mye familie ombord? Det kan være en idé og f.eks. slå variablene sammen til en gruppe. På samme måte som at størrelsen på familien kan være interessant kan det også være spennende å se om det vil ha noe betydning om man er alene. 

PassengerId er ikke relevant, den en variabel for å kunne referere til passasjerer.

Inspirasjon: <https://www.kaggle.com/code/allohvk/titanic-advanced-eda?scriptVersionId=77739368>

## Utforsking av dataen

### Behandling av manglende verdier(NA\`s)

Bruker skim fra pakken skimr for å få en oversikt over dataen:

```{r}

skimr::skim(Titanic)

```

Her får vi vite at det 891 rander og at 5 av de tolv kolonnene er av typen "character". Det som er av mest interesse i outputen er kolonnen med "n_missing". Kolonnen "Cabin" har 687 manglende verdier. Det er rimelig å tenke seg at lugarnummeret ikke har så mye å si for overlevelsen, og at heller "Pclass" er viktigere for analysen. Med så mange manglende verdier blir det også vanskelig å lage nye variabler med hvilket dekk man var på. Da måtte man eventuelt gjort noen antagelser om at første klasse var på dekk A og B, men det blir jo nesten det samme som pclass og derfor ikke hensiktsmessig. Ettersom at datasettet ikker er så stort er det mer hensiktsmessig å fjerne hele kolonnen fremfor å fjerne alle randene med manglende verdier.

```{r, include=FALSE}

titanic <- titanic |> 
  select(-Cabin)
```

Alder er også en variabel som mangler 177. Denne kolonnen er litt mer problematisk. Som drøftet ovenfor kan man tenke seg at alder har mye å si for analysen. Datasettet er lite så det blir dumt å fjerne disse radene. En muligheter er å kunne fylle disse verdiene med gjennomsnittsalderen. En annen metode som blir diskutert i denne artikkelen: <https://www.kaggle.com/code/allohvk/titanic-missing-age-imputation-tutorial-advanced>, er f.eks. å se på tittel som "Master" for å indentifisere unge gutter.

```{r}

mean_age_master <- titanic |> 
  filter(grepl("Master", Name)) |> 
  summarise(mean(Age, na.rm = T)) |> 
  pull()


titanic <- titanic |> 
  mutate(Age = ifelse(is.na(Age) & (grepl("Master", Name)), 
                      yes = round(mean_age_master,0), 
                      no = Age))
```

Her finner vi gjennomsnittlig alder for personer med "Master" som tittel og implemterer dette i datasettet med en ifelse-statment.

```{r}
titanic |> 
  select(Age) |> 
  summarise(sum(is.na(Age))) |> 
  pull()
```

Likevel har vi fortsatt 173 manglende verdier. Andre fremmgangsmetoder som også blir nevnt i artikkelen er å bruke gjennomsnittsalderen for gitte klasser og kjønn.

```{r}

mean_age_menn_p <- rep(0,3)
mean_age_kvinne_p <- rep(0,3) 
for (i in 1:3)
{
  mean_age_menn_p[i] <- titanic |> 
    filter(Pclass == i &  Sex == "male") |> 
    summarise(round(mean(Age, na.rm = T),0)) |> 
    pull()
  
  mean_age_kvinne_p[i] <- titanic|> 
    filter(Pclass == i &  Sex == "female") |> 
    summarise(round(mean(Age, na.rm = T),0)) |> 
    pull()
}

mann_p3 <- "Moran, Mr. James"
mann_p2 <- "Williams, Mr. Charles Eugene"
mann_p1 <- "Woolner, Mr. Hugh"

kvinne_p3 <- "Moran, Miss. Bertha"
kvinne_p1 <- "Thorne, Mrs. Gertrude Maybelle"
kvinne_p2 <- "Keane, Miss. Nora A"

navn_med_na <- c(mann_p1, mann_p2, mann_p3,
                 kvinne_p1, kvinne_p2, kvinne_p3)

aldere <- c(mean_age_menn_p, mean_age_kvinne_p)

for (i in 1:3)
{
titanic <- titanic |> 
   mutate(Age = ifelse(is.na(Age) & Sex == "male" & Pclass == i, 
                       mean_age_menn_p[i], 
                       Age)) |> 
  mutate(Age = ifelse(is.na(Age) & Sex == "female" & Pclass == i, 
                      mean_age_kvinne_p[i], 
                      Age)) 
}


for (i in 1:6)
{
  person_ald <- titanic |> 
    filter(Name == navn_med_na[i]) |> 
    pull(Age)
  
  stopifnot(person_ald == aldere[i])
}
```

Her finner vi først gjennomsnittsalderne på for kjønn gitt pclass, deretter finner vi seks tilfeldige navn for en gitt pclass som vi vet har manglende verdier. Så fyller vi datarammen med disse verdiene. For å sjekke at verdiene ble riktige kjører vi en løkke med en "stopifnot" metode for å sjekke at personene fikk riktig verdi.

Nå har vi kun 2 manglende verdier for embarked. Det burde nok gå greit å fjerne dem, men vi kan også prøve å utforske dataen før vi gjør det.

```{r}

titanic |> 
  filter(is.na(Embarked))
```

Det er her snakk om to kvinner som begge overlevde og var i første klasse. Datasette er ikke kjempe stort og det ville vært dumt å skulle miste rader med folk som overlevde. Vi kan utforske litt mer.

```{r}

titanic |> 
  filter(Sex == "female" & Pclass == 1) |> 
  group_by(Embarked, Pclass) |>
  summarise(mean_survived = mean(Survived), antall = n())


```

Det vi kan tolke fra output er at de fleste kvinner som er i førseklasse overlevde, uavhengig av hvor de kom ombord. Derfor tenker vi det er rimelig å fylle de manglende verdiene med tilfeldig trekk mellom "C" of "S", ettersom at de er de verdien som er mest sannsylige.

```{r}

tilfeldig_embarked <- sample(c("C", "S"), size = 1)

titanic <- titanic |> 
  mutate(Embarked = ifelse(is.na(Embarked),
                           yes = tilfeldig_embarked,
                           no = Embarked))
  
```

### Visualisering av data

Nå som vi har bearbeidet datarammen har vi lyst til å utforske dataen litt mer. Dette gjør vi for å få en bedre forståelse for ulike sammenhenger i dataen.

```{r}
titanic |> 
  group_by(Survived) |> 
  summarise(Antall = n(), 
            Andel = round(n()/891,2))
```

I følge dataen vi har er det kun 342 person som overlevde, mens det var 549 som ikke gjorde det. Har dette noe å si for f.eks. Pclass.

```{r}

titanic |> 
  ggplot(aes(x = Survived, fill = as.factor(Survived))) +
  geom_bar() +
  ylab("Antall") +
  facet_wrap(vars(Pclass))
```

Antallet som overlevde ser ut til å være ganske likt mellom klassene. Det er nok mer interesant å se på ovelevelsen som en andel av antallet.

```{r}
titanic |> 
  group_by(Pclass) |> 
  summarise(Survived_share = sum(Survived)/n())

titanic |> 
  group_by(Pclass) |> 
  summarise(Survived_share = sum(Survived)/n()) |>
  mutate(Klasse = c("1.Første", "2.Andre", "3.Tredje")) |> 
  ggplot(aes(x = Pclass,y = Survived_share, fill = Klasse)) +
  geom_col() +
  ylab("Prosent som overlede") +
  xlab("Overlevde")
```

Her får vi et tydligere bilde over overlevelse og hvilken klasse du er i. Vi ser at andel som overlevde blir betraktlig større desto høyre klasse klasse man er i. Kan kjønn ha noe betydning?

```{r}

titanic |> 
  group_by(Pclass,Sex) |> 
  summarise(Survived_share = sum(Survived)/n())|> 
  ggplot(aes(x = Pclass, y =Survived_share, fill = Sex)) +
  geom_col(position = position_dodge())+
  ylab("Andel som overlevde") +
  xlab("Klasse") +
  ggtitle("Fordeling av andel klasser og kjønn")

```

Her ser vi at det er en tydelig sammenheng mellom klasse og kjønn for overlevelse. Det ser ut som at kvinner i første og andre klasse har realtivt stor sannsynlighet for å overleve. Kvinner i tredje klasse ligger på rundt femti prosent. Andelen menn som overlevde er betraktlig lavere i alle klasser samenlignet med kvinner. Andel menn som overlevde i andre og tredje klasse er omtrent halvparten av det den er i første klasse, likevel er det å være mann i første klasse "dårligere" enn å være kvinne i tredjeklasse med tanke på overlevelse. Det viser seg at kjønn har større påvirkning på overlevelse fremfor hvilken klasse du er i, dette stemmer jo overens med at kvinner og barn går først når det evakueres. Det er kanskje da naturlig å se på hvordan alder spiller en rolle.

```{r}

titanic |> 
  mutate(
    Agegroup = cut(
      Age, 
      breaks = c(-Inf,20, 30, 40, 50, 60, Inf), 
      labels = c("0-20", "20-31", "31-40", "41-50", "51-60", "61+"))) |> 
  group_by(Agegroup,Sex, Pclass) |> 
  summarise(Andel = sum(Survived)/n())|>
  ggplot(aes(x = Agegroup, y= Andel, fill = Agegroup))+
  geom_col() +
  xlab("Aldersgrupper")+
  ylab("Andel overlevd")+
  facet_wrap(vars(Sex, Pclass))

```

```{r}

titanic |> 
  ggplot(aes(x = Survived, y = Age)) +
  geom_point()
  
  facet_wrap(vars(Pclass))

  
  
  
  
titanic |> 
  mutate(
    Agegroup = cut(
      Age, 
      breaks = c(-Inf,20, 30, 40, 50, 60, Inf), 
      labels = c("0-20", "20-31", "31-40", "41-50", "51-60", "61+"))) |> 
  group_by(Agegroup,Sex, Pclass) |> 
  summarise(Andel = sum(Survived)/n()) |> 
  ggplot(aes(x = Agegroup, y = Andel)) +
  geom_point() +
  geom_smooth(method = "lm")+
  facet_wrap(vars(Sex, Pclass))

```

```{r}

# Assuming 'titanic' is your dataframe
titanic |> 
  mutate(
    Agegroup = cut(
      Age, 
      breaks = c(-Inf, 20, 30, 40, 50, 60, Inf), 
      labels = c("0-20", "20-30", "31-40", "41-50", "51-60", "61+")),
    Agegroup_mid = case_when(
      Agegroup == "0-20" ~ 10,
      Agegroup == "20-30" ~ 25,
      Agegroup == "31-40" ~ 35,
      Agegroup == "41-50" ~ 45,
      Agegroup == "51-60" ~ 55,
      Agegroup == "61+" ~ 70
    )
  ) |> 
  group_by(Agegroup, Agegroup_mid, Sex, Pclass) |> 
  summarise(Andel = sum(Survived)/n()) |> 
  ggplot(aes(x = Agegroup_mid, y = Andel)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(vars(Sex, Pclass)) +
  scale_x_continuous(breaks = c(10, 25, 35, 45, 55, 70), labels = c("0-20", "20-30", "31-40", "41-50", "51-60", "61+")) +
  labs(x = "Age Group", y = "Proportion Survived", title = "Survival Proportion by Age Group, Sex, and Pclass")



titanic %>%
  filter(!is.na(Age)) %>%
  group_by(Age, Sex, Pclass) %>%
  summarise(Andel = sum(Survived)/n()) %>%
  ggplot(aes(x = Age, y = Andel)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_wrap(vars(Sex, Pclass)) +
  labs(x = "Age", y = "Proportion Survived", title = "Survival Proportion by Age, Sex, and Pclass") +
  theme_minimal()

```

Deler inn i aldersgrupper for å letter kunne tolke dataen

Her ser vi mye av det samme som i plottet ovenfor, men med litt mer innsikt. Uansett aldersgruppe er det en høy andel av kvinner som overlever i første og andre klasse, derimot i tredje klasse var det en betraktlig mindre andel som overlevde uansett aldersgruppe, med untak av 61 år og eldre, noe som kanskje skyler et lite utvalg i denne gruppen. Menn ser vi at andelen overlevde er ganske lav uansett aldersgruppe. Likevel ser vi at de yngste mellom 0-20 har en liten fordel. Tendensen ser nærmest ut som at desto eldre du blir desto lavere blir andelen som overlever. Grafene gir oss ikke særlig tydlig svar på om alder egentlig spiller en rolle, men at det forsatt ser ut som at kjønn er den variabelen som har størst betydning.

Hva med prisen hvor mye de betalte, har det noe å si for overlevelsen.

![](images/clipboard-755930519.png)

```{r}

titanic |> 
  ggplot(aes(x = Fare)) +
  geom_histogram()

titanic |> 
  filter(Fare < 200) |> 
  mutate(Fare_group = ntile(Fare, 6)) |>
  mutate(Fare_group = factor(Fare_group, labels = c("Q1", "Q2", "Q3", "Q4", "Q5", "Q6"))) |> 
  group_by(Fare_group, Sex) |> 
  summarise(andel = sum(Survived)/n()) |> 
  ggplot(aes(x = Fare_group, y = andel, fill = Fare_group)) + 
  geom_col() +
  facet_wrap(vars(Sex))
```

Ettersom at fordlingen over hvor mye hver person betalte er høyre vridd har vi prøvd å dele dem inn i seks grupper, litt som for alder. Vi ser også at det er en del uteliggere, derfor har vi prøvd å filtrere disse bort. Det vi tolker fra grafene er at jo mer folk betalte for reisen desto større andel overlevde, spessielt hos menn. Funnet samsvarer også med grafen over at andelen menn i første klasse hadde en større andel overlevende. Tendensen er ikke like sterk hos kvinner. Noe som tyder på at det å være kvinner taler for at bilettprisen har mindre betydning for dem enn det den har hos menn.

```{r}

titanic |> 
  group_by(Embarked) |> 
  summarise(Antall = n())

titanic |> 
  group_by(Embarked, Pclass) |> 
  summarise(andel_overlevde = sum(Survived)/ n()) |> 
  ggplot(aes(x = Pclass, y = andel_overlevde, fill = Embarked )) +
  geom_col(position = position_dodge())

```

Plotter for hver enkelt pclass, ettersom at en stor andel av de som kommer fra Queenstown går rett i tredje klasse noe som har en tydlig sammenheng med overlevelse. Grafen viser ikke noe særlig sammenheng mellom hvor du gikk ombord og overlevelse. Dette gir gi også mening ettersom at, det egentlig ikke burde ha noe å si.

Oppsumer hva vi har fått ut fra plottene, hva slags sammenhenger har vi lært???? Kan plottene bli bedre.

## Nye variabler

```{r}

titanic <- titanic |> 
  mutate(Family_size = Parch + SibSp + 1) |> 
  mutate(alone = ifelse(Family_size == 1, 1, 0)) |> 
  select(-Parch, -SibSp, -Ticket, -PassengerId, -Name) |> 
  mutate(Pclass = as.factor(Pclass),
         alone = as.factor(alone),
         Survived = as.factor(Survived))

```

Skriv litt her,

## Maskinlæring

### Lasso

```{r}
set.seed(3170)
split <- initial_split(titanic)
titanic_train <- training(split)
titanic_test <- testing(split)


lasso_recipe <- 
  recipe(Survived ~ ., data = titanic_train) |>
  step_dummy(Sex, Embarked, alone, Pclass)


lasso_model <- 
  logistic_reg(penalty = tune(), mixture = 1) |> 
  set_engine("glmnet") |> 
  set_mode("classification")


wflow_lasso <- 
  workflow() |> 
  add_recipe(lasso_recipe) |> 
  add_model(lasso_model)



penalty_grid <- grid_regular(penalty(range = c(-4, -1)), levels = 100)


folds <- vfold_cv(titanic_train, 5, strata = Survived)

doParallel::registerDoParallel()

lasso_tune <- 
  wflow_lasso |> 
  tune_grid(resamples = folds, grid = penalty_grid)
```

Se på tuningen:

```{r}
lasso_tune |>
  collect_metrics() |> 
  filter(.metric != "brier_class") |> 
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  )) +
  geom_line(size = 1.5) +
  facet_wrap(~.metric, scales = "free", nrow = 2) +
  scale_x_log10() +
  theme(legend.position = "none") +
  ggtitle("Modellens prestasjon for ulike verdier av lambda")+
  xlab("Straff(lambda)") +
  ylab("Gjennomsnit")
  

```

```{r}
beste_lamda <- select_best(lasso_tune, metric = "roc_auc")
beste_lamda

lasso_fit <- finalize_workflow(wflow_lasso, beste_lamda) |> 
  fit(data = titanic_train)
```

Nå er modellen fitta.

Accuarcy

```{r}
predict(lasso_fit, titanic_test) |> 
  bind_cols(titanic_test) |> 
  accuracy(truth = Survived, estimate = .pred_class)
```

Roc_curve:

```{r}
auc_lasso <- 
  predict(lasso_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_auc(Survived, .pred_0) |> 
  pull(.estimate)

lasso_roc <- predict(lasso_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_curve(Survived, .pred_0)

lasso_roc |>   
  ggplot(aes(x = 1 - specificity, y = sensitivity)) + 
  geom_path(col = "blue") +
  geom_abline(slope = 1, linetype = "dashed") +
  coord_equal()+
  annotate("text", x = 0.6, y = 0.1, 
           label = paste("AUC =", round(auc_lasso,3) ), size = 5) +
  theme_bw() +
  ggtitle("ROC-Kurve")



```

Hva modellen syntes var viktig:

```{r}
lasso_fit |> 
  extract_fit_parsnip() |> 
  vip::vi() |> 
  ggplot(aes(y = reorder(Variable, Importance), 
             x = Importance, fill = Sign)) +
  geom_col() +
  theme(legend.position = "none") + 
  ggtitle("Viktigheten av ulike variabler") +
  xlab("Betydning") +
  ylab("Variabler")
```

Conf mat:

```{r}
library(cvms)

prediksjoner_lasso <- predict(lasso_fit, titanic_test) |> 
  bind_cols(titanic_test)

feilmatrise_lasso <- prediksjoner_lasso |> 
  conf_mat(Survived, .pred_class)

riktigmatrise_lasso <- as.tibble(feilmatrise_lasso$table) |> 
  mutate(Prediction = ifelse(Prediction == 0, "Not survived", "Survived")) |> 
  mutate(Truth = ifelse(Truth == 0, "Not survived", "Survived"))

plot_confusion_matrix(riktigmatrise_lasso, "Prediction", "Truth", "n", 
                      add_normalized = F,
                      add_row_percentages = F,
                      add_col_percentages = F) +
  xlab("Faktisk") +
  ylab("Predikert") +
  ggtitle("Feilmatrise Lasso")

```

### Random forest

https://stackoverflow.com/questions/75735619/how-to-get-a-variable-importance-graph-from-a-random-forest-using-tidymodels-and

```{r}
set.seed(3170)

rf_mod <- rand_forest(
  mtry = tune(),
  trees = tune(),
  min_n = tune()
) |> 
  set_engine("ranger", importance = "impurity") |>  
  # For å kunne bruke Vip pakken
  set_mode("classification")


rf_rec <- recipe(Survived~., data = titanic_train)

rf_wflow <- workflow() |> 
  add_recipe(lasso_recipe) |> 
  add_model(rf_mod)


rf_grid <- grid_regular(
  mtry(range = c(2, 7)),
  min_n(range = c(2,7)),
  trees(range = c(100,1200)),
  levels = 5
)


doParallel::registerDoParallel()

tune_rf <- tune_grid(
  rf_wflow,
  resamples = folds,
  grid = rf_grid
)

tune_rf |> 
  collect_metrics() |> 
  filter(.metric == "roc_auc") |> 
  mutate(min_n = factor(min_n)) |> 
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "AUC") +
  facet_wrap(vars(trees))
```

```{r}

select_best(tune_rf, metric = "accuracy")
select_best(tune_rf, metric = "roc_auc")


```

```{r}

set.seed(3170)
beste_mtry_min_tree <- select_best(tune_rf, metric = "roc_auc")

rf_fit <- finalize_workflow(rf_wflow, beste_mtry_min_tree) |> 
  fit(titanic_train)


predict(rf_fit, titanic_test) |> 
  bind_cols(titanic_test) |> 
  accuracy(Survived, .pred_class)
```

Litt lavere Accuarcy

```{r}
auc_rf <- 
  predict(rf_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_auc(Survived, .pred_0) |> 
  pull(.estimate)

rf_roc <- predict(rf_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_curve(Survived, .pred_0) 

rf_roc|>
  ggplot(aes(x = 1 - specificity, y = sensitivity)) + 
  geom_path(col = "blue") +
  geom_abline(slope = 1, linetype = "dashed") +
  coord_equal()+
  annotate("text", x = 0.6, y = 0.1, label = paste("AUC =", round(auc_rf,3) ), size = 5) +
  theme_bw() +
  ggtitle("ROC-Kurve")

```

```{r}
rf_fit |> 
  extract_fit_parsnip() |> 
  vip::vi() |> 
  ggplot(aes(y = reorder(Variable, Importance), x = Importance, fill = "#F8766D")) +
  geom_col() +
  theme(legend.position = "none") + 
  ggtitle("Viktigheten av ulike variabler") +
  xlab("Betydning") +
  ylab("Variabler")
```

```{r}

prediksjoner_rf <- predict(rf_fit, titanic_test) |> 
  bind_cols(titanic_test)

feilmatrise_rf <- prediksjoner_rf |> 
  conf_mat(Survived, .pred_class)

riktigmatrise_rf <- as.tibble(feilmatrise_rf$table) |> 
  mutate(Prediction = ifelse(Prediction == 0, "Not survived", "Survived")) |> 
  mutate(Truth = ifelse(Truth == 0, "Not survived", "Survived"))

plot_confusion_matrix(riktigmatrise_rf, "Prediction", "Truth", "n", 
                      add_normalized = F,
                      add_row_percentages = F,
                      add_col_percentages = F) +
  xlab("Faktisk") +
  ylab("Predikert") +
  ggtitle("Feilmatrise Random Forest")

```

### Decision tree

```{r}

decision_model <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune(),
  min_n = tune()) |> 
  set_engine("rpart") |> 
  set_mode("classification")

decision_rec <- recipe(Survived ~ ., data = titanic_train) 


decision_wflow <- workflow() |> 
  add_recipe(lasso_recipe) |> 
  add_model(decision_model)

decision_tree_params <- parameters(decision_model) |> 
  update(
    cost_complexity = cost_complexity(),
    tree_depth = tree_depth(),
    min_n = min_n()
  )

decision_grid <- grid_regular(
  decision_tree_params,
  levels = 5
)

doParallel::registerDoParallel()

tune_decision <- tune_grid(
  decision_wflow,
  resamples = folds,
  grid = decision_grid,
)

tune_decision |> 
  collect_metrics() |> 
  filter(.metric == "roc_auc") |> 
  mutate(min_n = factor(min_n)) |> 
  ggplot(aes(cost_complexity, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "AUC") +
  facet_wrap(vars(tree_depth))

```

Lar tidymodels ta seg av ranges på ulike parameterer. Noe som vi ikke gjorde for random forest eller lasso.

```{r}

best_cost_depth_min <- select_best(tune_decision, metric = "roc_auc")
best_cost_depth_min

decision_fit <- finalize_workflow(decision_wflow, best_cost_depth_min) |> 
  fit(titanic_train)


predict(decision_fit, titanic_test) |> 
  bind_cols(titanic_test) |> 
  accuracy(Survived, .pred_class)
```

Dårligste Accuarcy så langt

```{r}

auc_decision <- 
  predict(decision_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_auc(Survived, .pred_0) |> 
  pull(.estimate)

decision_roc <- predict(decision_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_curve(Survived, .pred_0) 

decision_roc|>
  ggplot(aes(x = 1 - specificity, y = sensitivity)) + 
  geom_path(col = "blue") +
  geom_abline(slope = 1, linetype = "dashed") +
  coord_equal()+
  annotate("text", x = 0.6, y = 0.1, 
           label = paste("AUC =", round(auc_decision,3) ), size = 5) +
  theme_bw() +
  ggtitle("ROC-Kurve")

```

```{r}
library(rpart)
library(rpart.plot)

decision_final_fit <- finalize_workflow(decision_wflow, best_cost_depth_min) |> 
  last_fit(split)

final_tree <- extract_workflow(decision_final_fit)

final_tree |> 
  extract_fit_engine() |> 
  rpart.plot(roundint = FALSE)
```

For å bruke funkjsonen til rpart, må vi fitte på en annen måte, vi kunne ha brukt denne metodene med last_fit gjennom hele, men vi syntes det var greiere å kun jobbe med fit, isteden for å kjøre last_fit

```{r}

decision_fit |> 
  extract_fit_parsnip() |> 
  vip::vi() |> 
  ggplot(aes(y = reorder(Variable, Importance), x = Importance, fill = "#F8766D")) +
  geom_col() +
  theme(legend.position = "none") + 
  ggtitle("Viktigheten av ulike variabler decision tree") +
  xlab("Betydning") +
  ylab("Variabler")

```

```{r}

prediksjoner_decision <- predict(decision_fit, titanic_test) |> 
  bind_cols(titanic_test)

feilmatrise_decision <- prediksjoner_decision |> 
  conf_mat(Survived, .pred_class)

riktigmatrise_decision <- as.tibble(feilmatrise_decision$table) |> 
  mutate(Prediction = ifelse(Prediction == 0, "Not survived", "Survived")) |> 
  mutate(Truth = ifelse(Truth == 0, "Not survived", "Survived"))

plot_confusion_matrix(riktigmatrise_decision, "Prediction", "Truth", "n", 
                      add_normalized = F,
                      add_row_percentages = F,
                      add_col_percentages = F) +
  xlab("Faktisk") +
  ylab("Predikert") +
  ggtitle("Feilmatrise Decision tree")



```

### Xgboost

```{r}

xg_model <- boost_tree(
  trees = 1000,
  tree_depth = tune(),
  learn_rate = tune(),
  mtry = tune(),
  min_n = tune(),
  loss_reduction = tune(),
  sample_size = tune()
  )|> 
  set_engine("xgboost") |> 
  set_mode("classification")


xg_wflow <- workflow() |> 
  add_recipe(lasso_recipe) |> 
  add_model(xg_model)

xg_grid <- grid_latin_hypercube(
  tree_depth(),
  learn_rate(),
  finalize(mtry(), titanic_train),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  size = 50
)
 
doParallel::registerDoParallel()

tune_xg <- tune_grid(
  xg_wflow,
  resamples = folds,
  grid = xg_grid,
)

best_param_xg <- select_best(tune_xg, metric = "roc_auc")
best_param_xg
```

grid: https://juliasilge.com/blog/xgboost-tune-volleyball/, blir litt vanskelig å plotte

```{r}
set.seed(3170)
xg_fit <- finalize_workflow(xg_wflow, best_param_xg) |> 
  fit(titanic_train)

predict(xg_fit, titanic_test) |> 
  bind_cols(titanic_test) |> 
  accuracy(Survived, .pred_class)
```

```{r}
auc_xg <- 
  predict(xg_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_auc(Survived, .pred_0) |> 
  pull(.estimate)

xg_roc <- predict(xg_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_curve(Survived, .pred_0) 

xg_roc|>
  ggplot(aes(x = 1 - specificity, y = sensitivity)) + 
  geom_path(col = "blue") +
  geom_abline(slope = 1, linetype = "dashed") +
  coord_equal()+
  annotate("text", x = 0.6, y = 0.1, 
           label = paste("AUC =", round(auc_xg,3) ), size = 5) +
  theme_bw() +
  ggtitle("ROC-Kurve")


```

```{r}
xg_fit |> 
  extract_fit_parsnip() |> 
  vip::vi() |> 
  ggplot(aes(y = reorder(Variable, Importance), x = Importance, fill = "#F8766D")) +
  geom_col() +
  theme(legend.position = "none") + 
  ggtitle("Viktigheten av ulike variabler decision tree") +
  xlab("Betydning") +
  ylab("Variabler")
```

```{r}

prediksjoner_xg <- predict(xg_fit, titanic_test) |> 
  bind_cols(titanic_test)

feilmatrise_xg <- prediksjoner_xg |> 
  conf_mat(Survived, .pred_class)

riktigmatrise_xg <- as.tibble(feilmatrise_xg$table) |> 
  mutate(Prediction = ifelse(Prediction == 0, "Not survived", "Survived")) |> 
  mutate(Truth = ifelse(Truth == 0, "Not survived", "Survived"))

plot_confusion_matrix(riktigmatrise_xg, "Prediction", "Truth", "n", 
                      add_normalized = F,
                      add_row_percentages = F,
                      add_col_percentages = F) +
  xlab("Faktisk") +
  ylab("Predikert") +
  ggtitle("Feilmatrise XGboost")

```

### Sammenligne modeller

```{r}




```

```{r}
lasso_roc <- lasso_roc |> 
  mutate(type = "Lasso")

rf_roc <- rf_roc |> 
  mutate(type = "Random forest")

decision_roc <- decision_roc |> 
  mutate(type = "Decision tree")

xg_roc <- xg_roc |> 
  mutate(type  = "XGboost")

auc_alle <- lasso_roc |> 
  bind_rows(rf_roc, decision_roc, xg_roc)


auc_alle |> 
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = type)) + 
  geom_path() +
  geom_abline(slope = 1, linetype = "dashed") +
  coord_equal()+
  theme_bw() +
  ggtitle("ROC-Kurver")
```

```{r}
prediksjoner_lasso <- prediksjoner_lasso |> 
  mutate(type = "Lasso")

prediksjoner_rf <- prediksjoner_rf |> 
  mutate(type = "Random forest")

prediksjoner_decision <- prediksjoner_decision |> 
  mutate(type = "Decision tree")

prediksjoner_xg <- prediksjoner_xg |> 
  mutate(type = "XGboost")

alle_prediksjoner <- prediksjoner_lasso |> 
  bind_rows(prediksjoner_rf, 
            prediksjoner_decision, 
            prediksjoner_xg)


alle_prediksjoner |> 
  group_by(type) |> 
  accuracy(Survived,.pred_class)

```

Litt høyere AUC

Tune_rf er en flaskehals i koden.
