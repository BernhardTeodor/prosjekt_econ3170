---
title: "Prosjekt"
format: html
editor: visual
---

# Titanic katastrofen- ECON 3170

## *Introduksjon*

I denne oppgaven skal vi - ved hjelp av ulike maksinlæringsmodeller - forsøke å predikere om passasjerer på Titanic overlevde eller ikke. Datasettet er hentet fra kaggle, og oppgaven er inspirert av Kaggles maksinlæringskonkurranse (Kaggle). Vi innleder med å innspisere datasettet, og forsøke å få oversikt over de ulike variablene, og omfanget av manglende verdier. Vi vil så forsøke å behandle de manglende verdiene, og tilpasse de slik at de blir enklere å bruke i treningen av maskinlæringsmodellene. Videre vil vi inspisere datasettet ved hjelp av plots for å forsøke å se sammenhengen mellom ulike variabler, og andelen overlevende. Vi vil så tilpasse parametere og hyperparametere for å forsøke å få så presise modeller som mulig. Til slutt vil vi implementere modellene i et dashboard hvor en kan finne overlevelsessansynlighet for en selvvalgt karakter.

## Pakker

I prosjetet kommer vi hovedsaklig til å benytte oss av to pakker: tidyverse og tidymodels. Begge pakkene er samlinger av mange ulike pakker. Vi kommer i hovedsak til å bruke Tidyverse til manipulering og visualisering av data, og Tidymodels til maskinlæring.

```{r, message = FALSE}
library(tidyverse) 
library(tidymodels) 
```

```{r, include = FALSE}
options(dplyr.summarise.inform = FALSE)
options(readr.show_cols_spec= FALSE)
options(readr.num_columns = 0)
```

## Data

```{r}
titanic <- suppressMessages(read_csv("Titanic-Dataset.csv"))
glimpse(titanic[1,])
```

#NOTE: "suppressMessages", for å unngå output melding.

Datasettet består av 891 observasjoner med 12 variabler, og er en oversikt over et utvalg av passasjerene ombord på Titanic. Første kolonne er PassengerId som gir hver observasjon en unik ID. Den andre kolonnen er Survival; en binær variabel som indikerer om passasjeren overlevde (1) eller ikke (0). Tredje kolonne er Pclass som forteller hvilken klasse passasjeren var på. Fjerde kolonne, Name, viser navnene til hver enkelt passasjer. Kolonne fem, Sex, er en kategorisk variabel som betegner kjønnet til passasjeren. Den sjette kolonnen, Age, er en kontinuerlig variabel som gir alderen til passasjeren. Kolonne sju, SibSp, er en variabel som viser antallet søsken eller ektefeller ombord på Titanic. Kolonne åtte, Parch viser antallet foreldre eller barn ombord.Nienede kolonne, Ticket, viser bilettnummeret til passasjeren Tiende kolonne, Fare, betegner prisen passasjeren brukte på biletten. Kolonne elleve, Cabin, er lugarnummeret til passasjeren. Embarked, den tolvte kolonnen er en kategorisk variabel som viser hvor passasjeren gikk på. hvor "C" er Cherbourg, "Q" er Queenstown og "S" er Southampton.

Kilde: (Kaggle)

```{r}
head(titanic)
```

Pclass og Fare virker veldig spennede, de fleste har nok sett filmen og der blir tydligfremstilt at hvis du er i første klasse har du en større sjanse for å overleve. Samme med Fare, hvis du har betalt mye for biletten indikerer dette en høyere klasse som kan hinte til en større sannsynlighet for å overleve.

Cabin og Ticket er nok også verdier som har en sterk tilknytting med hvilken klasse du er i og hvor mye du betalte. Likevel blir det vannskelig å skulle si om noen overlever p.ga hvilket bilettnummer man har. Ved første øyekast ser det ut som at lugar variablen har mange manglende verdier. Hva den faktiske lugaren var er nok kanskje ikke altfor interessant, men hvilket dekk den ligger på kunne vært av stor interesse. Ettersom at dekket har mye å si for om du klarte å komme deg ut i tide.

Alder og kjønn er igjen ganske interessante variabler. Vi kjenner jo alle til "Kvinner og barn først". Her vil det nok være interessant å manipulere dataen for å fremmheve om vedkommende er et barn eller ikke. En annen dimensjon kan også være om personen blir ansett som gammel eller ikke, ettersom at disse gruppen antaglivis får prioritet under evakuering av skipet. Samt også kombinere disse verdiene med hvilken klasse de var i.

Navn er litt "tricky". Man kan gjerne tenke seg at naven til noen ikke er av stor betydning når det kommer til overlevelse som forsåvidt kan stemme. Likevel inkluderer navene tittler so f.eks mrs og master, og dette kan igjen være interessant.

Embarked er igjen variabel det blir litt vannskelig å si noe om, ettersom at det er kun tre forskjellige steder, som egentlig ikke burde ha særlig stor betydning. På den andre siden kan det være en korrelasjon mellom hvor man gikk om bord og hvilken klassen man er i.

Parch og Sibsp er en ganske interessante variabler. Kan det være noe sammenheng mellom hvor stor familie du har ombord og overlevelse.

PassengerId vikrer ikke veldig relevant, den virker litt mer som en variabel for å kunne referere til passasjer og den har nok mest sannsynlig ikke noe å gjøre med overlevelsen.

(Trenger vi denne gjennomgangen?)

*Inspirasjon (Allohvk)*

## Utforsking av dataen

### Behandling av manglende verdier(NA\`s)

```{r}
skimr::skim(titanic)
```

Vi bruker funksjonen skim fra skimr pakken for å skaffe en oversikt over dataen. Det mest interresante i utskriften er kolonnen "n_missing" som viser hvor mange manglende verdier det er per variabel. Dersom vi ser på variabelen "Cabin" ser vi at den har 687 manglende verdier. Det er rimelig å anta at selve lugarnummeret ikke er så viktig for å predikere overlevelse, og at variabler som Pclass da vil være til større hjelp. Dersom man hadde gjort noen antagelser om hvordan dekkene var organisert kunne en brukt for eksempel Pclass og Fare til å forsøke å estimere lugarnummeret, men ettersom dette vil bli noe upresist og kunne resultert i uheldige utslag på prediksjonene - som følge av et lite datasett - velger vi istedenfor å bare fjerne hele variabelen.

```{r}
titanic <- titanic |> 
  select(-Cabin)
```

Variabelen Age mangler 177 verdier, noe som kan være problematisk ettersom vi tenker at alder kan være viktig en viktig indikator for om noen overlevde eller ikke. Siden datasettet ikke er så stort velger vi å forsøke å fylle de manglende verdiene med gjennomsnittsalderen til passasjerer som deler tittel, og reiser med samme klasse (Pclass). Ved å dele inn etter både tittel og klasse forsøker vi å unngå at for mange observasjoner får den samme alderen, noe som kan bidra til å påvirke presisjonen til modellene.

Inspirasjonen er hentet fra artikkelen til *Allohvk*

```{r}
#Lager lister til å fylle inn verdiene
master.mean <- list() 
mr.mean <- list()
mrs.mean <- list()
miss.mean <- list()


#Setter opp en for-loop til å finne gjennomsnittet for alle med en gitt tittel, i en gitt klasse
for (i in 1:3){
  for (j in c("Master", "Mr.", "Mrs.", "Miss")) {
    if (j == "Master"){
      master.mean[[i]] <- titanic |> 
        filter(grepl("Master.", Name, fixed = TRUE), Pclass == i, Sex == "male") |> 
        summarise(mean_age = mean(Age, na.rm = TRUE)) |> 
        pull(mean_age)
    } else if(j == "Mr."){
      mr.mean[[i]] <- titanic |> 
        filter(grepl("Mr.", Name, fixed = TRUE), Pclass == i, Sex == "male") |> 
        summarise(mean_age = mean(Age, na.rm = TRUE)) |> 
        pull(mean_age)
    } else if (j == "Mrs.") {
      mrs.mean[[i]] <- titanic |> 
        filter(grepl("Mrs.", Name, fixed = TRUE), Pclass == i, Sex == "female") |> 
        summarise(mean_age = mean(Age, na.rm = TRUE)) |> 
        pull(mean_age)
    } else if(j == "Miss") {
      miss.mean[[i]] <- titanic |> 
        filter(grepl("Miss.", Name, fixed = TRUE), Pclass == i, Sex == "female") |> 
        summarise(mean_age = mean(Age, na.rm = TRUE)) |> 
        pull(mean_age)
    }
  }
}


#Fyller inn de manglende verdiene
for (i in 1:3){
  titanic <- titanic |> 
    mutate(Age = ifelse(grepl("Mr.", Name, fixed = T) & Pclass == i & is.na(Age), mr.mean[[i]], Age)) |> 
    mutate(Age = ifelse(grepl("Miss", Name, fixed = T) & Pclass == i & is.na(Age), miss.mean[[i]], Age)) |> 
    mutate(Age = ifelse(grepl("Mrs.", Name, fixed = T) & Pclass == i & is.na(Age), mrs.mean[[i]], Age)) |> 
    mutate(Age = ifelse(grepl("Master", Name, fixed = T) & Pclass == i & is.na(Age), master.mean[[i]], Age))
}


```

Vi fyller inn de manglende verdiene ved å ta utgangspunkt i titlene - Master, Mr. , Mrs. , Miss. - og finner gjennomsnittsalderen for klassen de tilhører, og fyller dette inn i datasettet. Ettersom det eksisterer flere titler som vi ikke dekket sjekker vi om vi finner flere manglende verdier, og forsøker samme metode for å sette inn verdiene.

```{r}
#Sjekker om det er fler manglende verider
titanic |> 
  filter(is.na(Age))

#Finner gjennomsnittet for tittel gitt klasse
mean.dr.p1 <- titanic |> 
  filter(grepl("Dr.", Name, fixed = TRUE) & Pclass == 1) |> 
  summarise(round(mean(Age, na.rm = TRUE))) |> 
  pull()

#Setter inn for verdien
titanic <- titanic |> 
  mutate(Age = ifelse(is.na(Age), mean.dr.p1, Age))
```

Fra utskriften til skimr funksjonen ser vi at det nå kun mangler 2 verdier for variabelen Embarked. Vi undersøker disse nærmere:

```{r}
titanic |> 
  filter(is.na(Embarked))
```

Vi ser at de manglende verdiene er for to kvinner, som begge overlevde, og som reiste med første klasse. For å opprettholde variasjonen i datasettet, og bevare flest mulig av observasjonene vi ønsker å predikere, vil vi forsøke å beholde observasjonene ved å fylle inn en verdi for Embarked.

```{r}
titanic |> 
  filter(Sex == "female" & Pclass == 1) |> 
  group_by(Embarked, Pclass) |>
  summarise(mean_survived = mean(Survived), antall = n())
```

Det vi kan tolke fra utskriften er at de fleste kvinnene som reiste med førsteklasse overlevde, uavhengig av hvor de gikk ombord. Det vil derfor være rimelig å fylle de manglende verdiene med et tilfeldig trekk mellom "C" og "S", ettersom disse var de vanligste stedene å gå ombord.

```{r}
tilfeldig_embarked <- sample(c("C", "S"), size = 1)

titanic <- titanic |> 
  mutate(Embarked = ifelse(is.na(Embarked),
                           yes = tilfeldig_embarked,
                           no = Embarked))

paste("Det er",sum(is.na(titanic)), "NAs datasettet")
```

### Visualisering av data

Når vi nå har bearbeidet dataene ønsker vi å utforske de ytterligere, for å få et bedre inntrykk av sammenhengene i dataene.

```{r}
titanic |> 
  group_by(Survived) |> 
  summarise(Antall = n())
```

Vi ser her at det kun er 342 passasjerer som overlevde, og at det var 549 passasjerer som omkom. Vi ønsker først å se på hvordan antall overlevende fordeler seg på klassen de reiste med. Antallet overlevende ser ut til å være ganske likt mellom klassene. Å se på andelen overlevende fordelt på klasse kan derfor gi et bedre inntrykk.

```{r}
titanic |> 
  group_by(Pclass) |> 
  summarise(Overlevelsesandel = sum(Survived)/n())
```

Vi ser av utskriften at andelen som overlevde er betydelig høyere for klasse 2 og 1 enn for klasse 2. Videre ønsker vi å undersøke betydningen til kjønn. Vi finner Overlevelsesandelen, fordelt på kjønn, fordelt på klasse.

```{r}
library(tidyverse)

titanic |> 
  group_by(Pclass,Sex) |> 
  summarise(Overlevelsesandel = sum(Survived)/n()) |> 
  ggplot(aes(x = Pclass, y = Overlevelsesandel, fill = Sex)) +
  geom_col(position = position_dodge()) +
  ylab("Andel som overlevde") +
  xlab("Klasse") +
  ggtitle("Figur 1.1 - Fordeling over andel, klasser og kjonn") +
  scale_fill_brewer(palette = "Set1")
```

Her ser vi at det er en tydelig sammenheng mellom klasse og kjønn for overlevelse. Det ser ut som at kvinner i første og andre klasse har realtivt stor sannsynlighet for å overleve. Kvinner i tredje klasse ligger på rundt femti prosent. Andelen menn som overlevde er betraktlig lavere i alle klasser samenlignet med kvinner. Andel menn som overlevde i andre og tredje klasse er omtrent halvparten av det den er i første klasse, likevel er det å være mann i første klasse "dårligere" enn å være kvinne i tredjeklasse med tanke på overlevelse. Det viser seg at kjønn har større påvirkning på overlevelse fremfor hvilken klasse du er i, dette stemmer jo overens med at kvinner og barn går først når det evakueres. Det er kanskje da naturlig å se på hvordan alder spiller en rolle.

Av diagrammet kan en se at det er en markant forskjell på overlevelsesandelen for kvinner og menn, for alle klasser. En kan også se at observasjonen

```{r}
titanic |> 
  ggplot(aes(x = Age, fill = Sex)) +
  geom_histogram() +
  facet_wrap(vars(Survived)) +
  scale_fill_brewer(palette = "Set1")
```

Det fremkomer ingen tydelelig sammenheng, vi deler inn i aldersgrupper, og ser på andelen overlevne i ulike aldersgrupper fordelt på kjønn

```{r}

titanic |> 
  mutate(
    Agegroup = cut(
      Age, 
      breaks = c(-Inf,20, 30, 40, 50, 60, Inf), 
      labels = c("0-20", "20-31", "31-40", "41-50", "51-60", "61+"))) |> 
  group_by(Agegroup,Sex) |> 
  summarise(Andel = sum(Survived)/n())|>
  ggplot(aes(x = Agegroup, y= Andel, fill = Agegroup))+
  geom_col() +
  scale_fill_brewer(palette = "Set3") +  
  xlab("Aldersgrupper") +
  ylab("Andel overlevd") +
  facet_wrap(vars(Sex))
```

Vi ser at det er en svak sammenheng mellom alder og overlevelse. Den laveste overlevelsesraten er for menn i alderen 20-31, noe som gir menging ettersom disse trolig måtte vente lengst på redningsbåt. For kvinner er tendensen noe lik, men her er det heller ingen sterk sammenheng. Det er også viktig å nevne at sammenhengen vi ser kan være noe spuriøs. Her kan for eksempel Pclass være viktig.

Hva med prisen hvor mye de betalte, har det noe å si for overlevelsen.

```{r, message=FALSE}

titanic |> 
  ggplot(aes(x = Fare)) +
  geom_histogram(bins = 30)

titanic |> 
  filter(Fare < 200) |> 
  mutate(Fare_group = ntile(Fare, 6)) |>
  mutate(Fare_group = factor(Fare_group, labels = c("Q1", "Q2", "Q3", "Q4", "Q5", "Q6"))) |> 
  group_by(Fare_group, Sex) |> 
  summarise(andel = sum(Survived)/n()) |> 
  ggplot(aes(x = Fare_group, y = andel, fill = Fare_group)) + 
  geom_col() +
  scale_fill_brewer(palette = "Set1") +
  facet_wrap(vars(Sex))
```

Ettersom at fordlingen over hvor mye hver person betalte er høyrevridd har vi prøvd å dele dem inn i seks grupper, slik som for alder. Vi ser også at det er en del uteliggere, derfor har vi prøvd å filtrere disse bort. Det vi tolker fra grafene er at jo mer folk betalte for reisen desto større andel overlevde, spessielt hos menn. Funnet samsvarer også med grafen over at andelen menn i første klasse hadde en større andel overlevende. Tendensen er ikke like sterk hos kvinner. Noe som tyder på at det å være kvinner taler for at billettprisen har mindre betydning for dem enn det den har hos menn.

```{r}
titanic |> 
  group_by(Embarked, Pclass) |> 
  summarise(andel_overlevde = sum(Survived)/ n()) |> 
  ggplot(aes(x = Pclass, y = andel_overlevde, fill = Embarked )) +
  geom_col(position = position_dodge())
```

Grafen viser ikke noe særlig sammenheng mellom hvor du gikk ombord og overlevelse. Dette gir gi også mening ettersom at, det egentlig ikke burde ha noe å si.

Vi kan se av grafene at det i hovedsak er kjønn og hvilken klasse en tilhører som har sterkest sammenheng med overlevelsen. Vi ser at hvor mye biletten kostet har noe å si for overlevelse, men denne sammengen er sterkest for menn, og at hvor en gikk på ikke har så mye å si. Alder har mest å si for menn.

## Nye variabler

Vi ser at den kan være hensiktsmessig å formalisere noen av variablene, og lage nye variabler. Dette kan forbedrer modellens ytelse, gjør resultatene lettere å forstå og kan gi ny innsikt.

Vi velger å lage en dummy variabel for om man er mindreåring eller ikke, en for hvor stor familie personen reiser med, og antall personer per billett. Inspirasjon hentet (Donges, 2018).

```{r}
titanic <- titanic |> 
  add_count(Ticket, name = "Person_per_ticket") |> 
  mutate(Minor = ifelse(Age < 18, 1, 0),
         Family_size = SibSp+Parch,
         Alone = ifelse(Family_size == 0, 1, 0)) |> 
  select(-c(Name, Ticket, SibSp, Parch, PassengerId)) |> 
  mutate(Pclass = as.factor(Pclass),
         Alone = as.factor(Alone),
         Survived = as.factor(Survived),
         Minor = as.factor(Minor),
         Sex = as.factor(Sex),
         Embarked = as.factor(Embarked))
```

## Maskinlæring

Før vi tilpasser modellene vi ønsker å bruke, deler vi datasettet inn i trening og test sett. Dataene deles inn i en 80/20 fordeling hvor variabelen Survived skal være jevnt fordelt.

```{r}
set.seed(3170)
titanic_split<- initial_split(titanic, prop = .8, strata = Survived)
titanic_train <- training(titanic_split)
titanic_test <- testing(titanic_split)
titanic_split
```

Lager en recepie:

```{r}
titanic_recipe <- 
  recipe(Survived ~ ., data = titanic_train) |>
  step_dummy(Sex, Embarked, Alone, Pclass, Minor)
```

### Lasso

```{r}
lasso_model <- 
  logistic_reg(penalty = tune(), mixture = 1) |> 
  set_engine("glmnet") |> 
  set_mode("classification")


wflow_lasso <- 
  workflow() |> 
  add_recipe(titanic_recipe) |> 
  add_model(lasso_model)

folds <- vfold_cv(titanic_train, 5, strata = Survived)

penalty_grid <- grid_regular(penalty(range = c(-4, -1)), levels = 100)

doParallel::registerDoParallel() # Parallelprogramering for raskere tune

lasso_tune <- 
  wflow_lasso |> 
  tune_grid(resamples = folds, grid = penalty_grid)

lasso_tune |>
  collect_metrics() |> 
  filter(.metric != "brier_class") |> 
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  )) +
  geom_line(size = 1.5) +
  facet_wrap(~.metric, scales = "free", nrow = 2) +
  scale_x_log10() +
  theme(legend.position = "none") +
  ggtitle("Modellens prestasjon for ulike verdier av lambda")+
  xlab("Straff(lambda)") +
  ylab("Gjennomsnit")
```

Vi setter opp lasso modellen og tuner den. Plottet viser hvordan accuracy og roc_auc utvikler seg for ulike verdier av lambda.

```{r}
beste_lamda <- select_best(lasso_tune, metric = "roc_auc")
beste_lamda

lasso_fit <- finalize_workflow(wflow_lasso, beste_lamda) |> 
  fit(data = titanic_train)
```

Bruker den beste roc_auc verdien i modellen og tilpasser modellen med denne verdien.

```{r}
predict(lasso_fit, titanic_test) |> 
  bind_cols(titanic_test) |> 
  accuracy(truth = Survived, estimate = .pred_class)
```

```{r}
auc_lasso <- 
  predict(lasso_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_auc(Survived, .pred_0) |> 
  pull(.estimate)

lasso_roc <- predict(lasso_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_curve(Survived, .pred_0)

lasso_roc |>   
  ggplot(aes(x = 1 - specificity, y = sensitivity)) + 
  geom_path(col = "blue") +
  geom_abline(slope = 1, linetype = "dashed") +
  coord_equal()+
  annotate("text", x = 0.6, y = 0.1, 
           label = paste("AUC =", round(auc_lasso,3) ), size = 5) +
  theme_bw() +
  ggtitle("ROC-Kurve")
```

Her er et plott som viser roc_auc til lasso modellen.

```{r}
lasso_fit |> 
  extract_fit_parsnip() |> 
  vip::vi() |> 
  ggplot(aes(y = reorder(Variable, Importance), 
             x = Importance, fill = Sign)) +
  geom_col() +
  theme() + 
  ggtitle("Viktigheten av ulike variabler") +
  xlab("Betydning") +
  ylab("Variabler")
```

```{r}
library(cvms)

prediksjoner_lasso <- predict(lasso_fit, titanic_test) |> 
  bind_cols(titanic_test)

forvirringsmatrise_lasso <- prediksjoner_lasso |> 
  conf_mat(Survived, .pred_class)

riktigmatrise_lasso <- as.tibble(forvirringsmatrise_lasso$table) |> 
  mutate(Prediction = ifelse(Prediction == 0, "Not survived", "Survived")) |> 
  mutate(Truth = ifelse(Truth == 0, "Not survived", "Survived"))

plot_confusion_matrix(riktigmatrise_lasso, "Prediction", "Truth", "n", 
                      add_normalized = F,
                      add_row_percentages = F,
                      add_col_percentages = F) +
  xlab("Faktisk") +
  ylab("Predikert") +
  ggtitle("Forvirringsmatrise Lasso")
```

Konklusjon: Lasso oser godt.

### Random forest

```{r}
set.seed(3170)

rf_mod <- rand_forest(
  mtry = tune(),
  trees = tune(),
  min_n = tune()
) |> 
  set_engine("ranger", importance = "impurity") |>  
  # For å kunne bruke Vip pakken
  set_mode("classification")



rf_wflow <- workflow() |> 
  add_recipe(titanic_recipe) |> 
  add_model(rf_mod)


rf_grid <- grid_regular(
  mtry(range = c(2, 7)),
  min_n(range = c(2,7)),
  trees(range = c(100,1200)),
  levels = 5
)


doParallel::registerDoParallel()

tune_rf <- tune_grid(
  rf_wflow,
  resamples = folds,
  grid = rf_grid
)

tune_rf |> 
  collect_metrics() |> 
  filter(.metric == "roc_auc") |> 
  mutate(min_n = factor(min_n)) |> 
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "AUC") +
  facet_wrap(vars(trees))
```

Tune rf, er en flaskehals. Vet ikke helt hv avi skal gjøre for å gjøre den raskere. Likevel leverer den stor os

```{r}
set.seed(3170)
beste_mtry_min_tree <- select_best(tune_rf, metric = "roc_auc")

rf_fit <- finalize_workflow(rf_wflow, beste_mtry_min_tree) |> 
  fit(titanic_train)


predict(rf_fit, titanic_test) |> 
  bind_cols(titanic_test) |> 
  accuracy(Survived, .pred_class)
```

```{r}
auc_rf <- 
  predict(rf_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_auc(Survived, .pred_0) |> 
  pull(.estimate)

rf_roc <- predict(rf_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_curve(Survived, .pred_0) 

rf_roc|>
  ggplot(aes(x = 1 - specificity, y = sensitivity)) + 
  geom_path(col = "blue") +
  geom_abline(slope = 1, linetype = "dashed") +
  coord_equal()+
  annotate("text", x = 0.6, y = 0.1, label = paste("AUC =", round(auc_rf,3) ), size = 5) +
  theme_bw() +
  ggtitle("ROC-Kurve")
```

```{r}
rf_fit |> 
  extract_fit_parsnip() |> 
  vip::vi() |> 
  ggplot(aes(y = reorder(Variable, Importance), x = Importance, fill = "#F8766D")) +
  geom_col() +
  theme(legend.position = "none") + 
  ggtitle("Viktigheten av ulike variabler") +
  xlab("Betydning") +
  ylab("Variabler")
```

```{r}
prediksjoner_rf <- predict(rf_fit, titanic_test) |> 
  bind_cols(titanic_test)

forvirringsmatrise_rf <- prediksjoner_rf |> 
  conf_mat(Survived, .pred_class)

riktigmatrise_rf <- as.tibble(forvirringsmatrise_rf$table) |> 
  mutate(Prediction = ifelse(Prediction == 0, "Not survived", "Survived")) |> 
  mutate(Truth = ifelse(Truth == 0, "Not survived", "Survived"))

plot_confusion_matrix(riktigmatrise_rf, "Prediction", "Truth", "n", 
                      add_normalized = F,
                      add_row_percentages = F,
                      add_col_percentages = F) +
  xlab("Faktisk") +
  ylab("Predikert") +
  ggtitle("Forvirringsmatrise Random Forest")
```

### Decision tree

```{r}

decision_model <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune(),
  min_n = tune()) |> 
  set_engine("rpart") |> 
  set_mode("classification")



decision_wflow <- workflow() |> 
  add_recipe(titanic_recipe) |> 
  add_model(decision_model)

decision_tree_params <- parameters(decision_model) |> 
  update(
    cost_complexity = cost_complexity(),
    tree_depth = tree_depth(),
    min_n = min_n()
  )

decision_grid <- grid_regular(
  decision_tree_params,
  levels = 5
)

doParallel::registerDoParallel()

tune_decision <- tune_grid(
  decision_wflow,
  resamples = folds,
  grid = decision_grid,
)

tune_decision |> 
  collect_metrics() |> 
  filter(.metric == "roc_auc") |> 
  mutate(min_n = factor(min_n)) |> 
  ggplot(aes(cost_complexity, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "AUC") +
  facet_wrap(vars(tree_depth))
```

Lar tidymodels ta seg av ranges på ulike parameterer. Noe som vi ikke gjorde for random forest eller lasso.

```{r}

best_cost_depth_min <- select_best(tune_decision, metric = "roc_auc")
best_cost_depth_min

decision_fit <- finalize_workflow(decision_wflow, best_cost_depth_min) |> 
  fit(titanic_train)


predict(decision_fit, titanic_test) |> 
  bind_cols(titanic_test) |> 
  accuracy(Survived, .pred_class)
```

Dårligste Accuarcy så langt

```{r}

auc_decision <- 
  predict(decision_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_auc(Survived, .pred_0) |> 
  pull(.estimate)

decision_roc <- predict(decision_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_curve(Survived, .pred_0) 

decision_roc|>
  ggplot(aes(x = 1 - specificity, y = sensitivity)) + 
  geom_path(col = "blue") +
  geom_abline(slope = 1, linetype = "dashed") +
  coord_equal()+
  annotate("text", x = 0.6, y = 0.1, 
           label = paste("AUC =", round(auc_decision,3) ), size = 5) +
  theme_bw() +
  ggtitle("ROC-Kurve")
```

```{r}
library(rpart)
library(rpart.plot)

decision_final_fit <- finalize_workflow(decision_wflow, best_cost_depth_min) |> 
  last_fit(titanic_split)

final_tree <- extract_workflow(decision_final_fit)

final_tree |> 
  extract_fit_engine() |> 
  rpart.plot(roundint = FALSE)
```

For å bruke funkjsonen til rpart, må vi fitte på en annen måte, vi kunne ha brukt denne metodene med last_fit gjennom hele, men vi syntes det var greiere å kun jobbe med fit, isteden for å kjøre last_fit

```{r}

decision_fit |> 
  extract_fit_parsnip() |> 
  vip::vi() |> 
  ggplot(aes(y = reorder(Variable, Importance), x = Importance, fill = "#F8766D")) +
  geom_col() +
  theme(legend.position = "none") + 
  ggtitle("Viktigheten av ulike variabler decision tree") +
  xlab("Betydning") +
  ylab("Variabler")
```

```{r}

prediksjoner_decision <- predict(decision_fit, titanic_test) |> 
  bind_cols(titanic_test)

forvirringsmatrise_decision <- prediksjoner_decision |> 
  conf_mat(Survived, .pred_class)

riktigmatrise_decision <- as.tibble(forvirringsmatrise_decision$table) |> 
  mutate(Prediction = ifelse(Prediction == 0, "Not survived", "Survived")) |> 
  mutate(Truth = ifelse(Truth == 0, "Not survived", "Survived"))

plot_confusion_matrix(riktigmatrise_decision, "Prediction", "Truth", "n", 
                      add_normalized = F,
                      add_row_percentages = F,
                      add_col_percentages = F) +
  xlab("Faktisk") +
  ylab("Predikert") +
  ggtitle("Forvirringsmatrise Decision tree")
```

### Xgboost

```{r}
xg_model <- boost_tree(
  trees = 1000,
  tree_depth = tune(),
  learn_rate = tune(),
  mtry = tune(),
  min_n = tune(),
  loss_reduction = tune(),
  sample_size = tune()
  )|> 
  set_engine("xgboost") |> 
  set_mode("classification")


xg_wflow <- workflow() |> 
  add_recipe(titanic_recipe) |> 
  add_model(xg_model)

xg_grid <- grid_latin_hypercube(
  tree_depth(),
  learn_rate(),
  finalize(mtry(), titanic_train),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  size = 50
)
 
doParallel::registerDoParallel()

tune_xg <- tune_grid(
  xg_wflow,
  resamples = folds,
  grid = xg_grid,
)

best_param_xg <- select_best(tune_xg, metric = "roc_auc")
best_param_xg
```

grid: https://juliasilge.com/blog/xgboost-tune-volleyball/, blir litt vanskelig å plotte

```{r}
xg_fit <- finalize_workflow(xg_wflow, best_param_xg) |> 
  fit(titanic_train)

predict(xg_fit, titanic_test) |> 
  bind_cols(titanic_test) |> 
  accuracy(Survived, .pred_class)
```

```{r}
auc_xg <- 
  predict(xg_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_auc(Survived, .pred_0) |> 
  pull(.estimate)

xg_roc <- predict(xg_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_curve(Survived, .pred_0) 

xg_roc|>
  ggplot(aes(x = 1 - specificity, y = sensitivity)) + 
  geom_path(col = "blue") +
  geom_abline(slope = 1, linetype = "dashed") +
  coord_equal()+
  annotate("text", x = 0.6, y = 0.1, 
           label = paste("AUC =", round(auc_xg,3) ), size = 5) +
  theme_bw() +
  ggtitle("ROC-Kurve")
```

```{r}
xg_fit |> 
  extract_fit_parsnip() |> 
  vip::vi() |> 
  ggplot(aes(y = reorder(Variable, Importance), x = Importance, fill = "#F8766D")) +
  geom_col() +
  theme(legend.position = "none") + 
  ggtitle("Viktigheten av ulike variabler decision tree") +
  xlab("Betydning") +
  ylab("Variabler")
```

```{r}

prediksjoner_xg <- predict(xg_fit, titanic_test) |> 
  bind_cols(titanic_test)

forvirringsmatrise_xg <- prediksjoner_xg |> 
  conf_mat(Survived, .pred_class)

riktigmatrise_xg <- as.tibble(forvirringsmatrise_xg$table) |> 
  mutate(Prediction = ifelse(Prediction == 0, "Not survived", "Survived")) |> 
  mutate(Truth = ifelse(Truth == 0, "Not survived", "Survived"))

plot_confusion_matrix(riktigmatrise_xg, "Prediction", "Truth", "n", 
                      add_normalized = F,
                      add_row_percentages = F,
                      add_col_percentages = F) +
  xlab("Faktisk") +
  ylab("Predikert") +
  ggtitle("forvirringsmatrise XGboost")
```

### MLP

Starter med å definere modell, og lage en workflow.

```{r}
mlp.model <- mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) |> 
  set_engine("nnet") |> 
  set_mode("classification")

mlp_wflow <- workflow() |> 
  add_model(mlp.model) |> 
  add_recipe(titanic_recipe)
```

Henter så ut hyperparameterne og implempenterer de i en grid ved hjelp av grid_latin_hypercube med 50 nivåer

```{r}
mlp_params <- extract_parameter_set_dials(mlp_wflow)
meterics <- metric_set(roc_auc, accuracy, brier_class)

grid <- grid_latin_hypercube(
  mlp_params,
  size = 50
)

doParallel::registerDoParallel()

mlp_tune <- tune_grid(
  mlp_wflow, 
  resamples = folds, 
  grid = grid,
  metrics = meterics,
  control = control_grid(save_pred = TRUE)
)
```

Henter deretter ut de beste parameterne, og tilpasser modellen

```{r}
logistic_param.reg <- select_best(mlp_tune, metric = "roc_auc") |>
  select(-.config)

fn.mlp_wflow <- mlp_wflow |> 
  finalize_workflow(logistic_param.reg)

fn.mlp_fit <- fn.mlp_wflow |> 
  fit(titanic_train)
```

Kjører prediksjoner, og plotter ROC-AUC.

```{r}

auc_mlp <- 
  predict(fn.mlp_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_auc(Survived, .pred_0) |> 
  pull(.estimate)

mlp_roc <- predict(fn.mlp_fit, titanic_test, type = "prob") |> 
  bind_cols(titanic_test) |> 
  roc_curve(Survived, .pred_0) 

mlp_roc |> 
   ggplot(aes(x = 1 - specificity, y = sensitivity)) + 
  geom_path(col = "blue") +
  geom_abline(slope = 1, linetype = "dashed") +
  coord_equal()+
  annotate("text", x = 0.6, y = 0.1, 
           label = paste("AUC =", round(auc_mlp, 3) ), size = 5) +
  theme_bw() +
  ggtitle("ROC-Kurve")
```

```{r}
library(NeuralNetTools)

fn.mlp_fit |> 
  extract_fit_parsnip() |> 
  vip::vi() |> 
  ggplot(aes(y = reorder(Variable, Importance), x = Importance, fill = "#F8766D"))+
  geom_col() +
  theme(legend.position = "none") + 
  ggtitle("Viktigheten av ulike variabler Multi Layer percepton") +
  xlab("Betydning") +
  ylab("Variabler")
```

```{r}
prediksjoner_mlp <- predict(fn.mlp_fit, titanic_test) |> 
  bind_cols(titanic_test)

forvirringsmatrise_xg <- prediksjoner_xg |> 
  conf_mat(Survived, .pred_class)

riktigmatrise_xg <- as.tibble(forvirringsmatrise_xg$table) |> 
  mutate(Prediction = ifelse(Prediction == 0, "Not survived", "Survived")) |> 
  mutate(Truth = ifelse(Truth == 0, "Not survived", "Survived"))

plot_confusion_matrix(riktigmatrise_xg, "Prediction", "Truth", "n", 
                      add_normalized = F,
                      add_row_percentages = F,
                      add_col_percentages = F) +
  xlab("Faktisk") +
  ylab("Predikert") +
  ggtitle("Forvirringsmatrise Multi-Layer Percepton")
```

## Kilder

-   Kaggle. *Titanic - Machine Learning from Disaster*. Kaggle. Hentet 1. november 2024 fra <https://www.kaggle.com/competitions/titanic>

-   Allohvk. *Titanic - Advanced EDA*. Kaggle. Hentet 1. november 2024 fra <https://www.kaggle.com/code/allohvk/titanic-advanced-eda?scriptVersionId=77739368>

-   Donges, N. (2018). *Predicting the survival of Titanic passengers*. Towards Data Science. Hentet 4. november 2024 fra <https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8>
